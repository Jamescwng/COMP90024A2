{
 "cells": [
  {
   "cell_type": "raw",
   "id": "02d1c3eb",
   "metadata": {},
   "source": [
    "https://medium.com/@prabowoyogawicaksana/elon-musks-twitter-sentiment-analysis-with-transformers-hugging-face-roberta-49b9e61b1433\n",
    "\n",
    "https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest\n",
    "\n",
    "https://huggingface.co/blog/sentiment-analysis-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57339280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import couchdb\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1ef1ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"admin\"\n",
    "password = \"admin\"\n",
    "couchserver = couchdb.Server(\"http://%s:%s@172.26.134.187:5984/\" % (user, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb104edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = couchserver['twitter']\n",
    "rows = db.view('_design/CrimeInfo/_view/TweetData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08fe98e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(row['id'], row['value']) for row in rows]\n",
    "#random.seed(0)\n",
    "#random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89290cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "numTweets = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3078258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data).rename({0: \"id\", 1: \"tweet\"}, axis='columns')[:numTweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c752634e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1520266206548213760</td>\n",
       "      <td>When you‚Äôre stuck underneath a pup  \\n\\n#Albus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1520342297728241664</td>\n",
       "      <td>Just posted a photo @ Organ Pipes National Par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>493802764774825984</td>\n",
       "      <td>Finally home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>493802997793570817</td>\n",
       "      <td>When Harry met Anna üòâüòçüíï http://t.co/8cnpbUlnVz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>493803077489537024</td>\n",
       "      <td>Home Weather - Temp: 12.4 ¬∞C. Wind: 8.9 km/h N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>495508603722158080</td>\n",
       "      <td>@Flipltb and did u hold hands during dinner.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>495508858987880448</td>\n",
       "      <td>Kicking people off tables coz we huuungry (@ C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>495509181151989761</td>\n",
       "      <td>Lol that's why crusaders are the best counter ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>495509245341614080</td>\n",
       "      <td>@takumiiiii0412 „Åì„Çå„ÅØÂèãÈÅî„ÅÆÂΩºÊ∞è„ÅÆÊÑöÁó¥„ÇíËÅû„ÅÑ„Å¶„Åü„ÅÆ(ÔΩ°ÔΩ•oÔΩ•ÔΩ°)üò¢ „Åã„ÄÅ„Åã„Åô...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>495509322269351936</td>\n",
       "      <td>Home Weather - Temp: 6.3 ¬∞C. Wind: 2.0 km/h NE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                              tweet\n",
       "0     1520266206548213760  When you‚Äôre stuck underneath a pup  \\n\\n#Albus...\n",
       "1     1520342297728241664  Just posted a photo @ Organ Pipes National Par...\n",
       "2      493802764774825984                                       Finally home\n",
       "3      493802997793570817     When Harry met Anna üòâüòçüíï http://t.co/8cnpbUlnVz\n",
       "4      493803077489537024  Home Weather - Temp: 12.4 ¬∞C. Wind: 8.9 km/h N...\n",
       "...                   ...                                                ...\n",
       "9995   495508603722158080       @Flipltb and did u hold hands during dinner.\n",
       "9996   495508858987880448  Kicking people off tables coz we huuungry (@ C...\n",
       "9997   495509181151989761  Lol that's why crusaders are the best counter ...\n",
       "9998   495509245341614080  @takumiiiii0412 „Åì„Çå„ÅØÂèãÈÅî„ÅÆÂΩºÊ∞è„ÅÆÊÑöÁó¥„ÇíËÅû„ÅÑ„Å¶„Åü„ÅÆ(ÔΩ°ÔΩ•oÔΩ•ÔΩ°)üò¢ „Åã„ÄÅ„Åã„Åô...\n",
       "9999   495509322269351936  Home Weather - Temp: 6.3 ¬∞C. Wind: 2.0 km/h NE...\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSentiment = data.copy(deep=True)\n",
    "dfSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31f183c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/m.rossi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# remove hashtags\n",
    "def hashtags(text):\n",
    "  hash = re.findall(r\"#(\\w+)\", text)\n",
    "  return hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f583fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emot.emo_unicode import UNICODE_EMOJI, EMOTICONS_EMO\n",
    "# translate emoji\n",
    "def emoji(text):\n",
    "  for emot in UNICODE_EMOJI:\n",
    "    if text == None:\n",
    "      text = text\n",
    "    else:\n",
    "      text = text.replace(emot, \"_\".join(UNICODE_EMOJI[emot].replace(\",\", \"\").replace(\":\", \"\").split()))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "170e2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove retweet username and tweeted at @username\n",
    "def remove_users(tweet):\n",
    "  '''Takes a string and removes retweet and @user information'''\n",
    "  tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) \n",
    "  # remove tweeted at\n",
    "  return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "258e068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove links\n",
    "def remove_links(tweet):\n",
    "  '''Takes a string and removes web links from it'''\n",
    "  tweet = re.sub(r'http\\S+', '', tweet) # remove http links\n",
    "  tweet = re.sub(r'bit.ly/\\S+', '', tweet) # remove bitly links\n",
    "  tweet = tweet.strip('[link]') # remove [links]\n",
    "  return tweet\n",
    "def clean_html(text):\n",
    "  html = re.compile('<.*?>')#regex\n",
    "  return html.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43afcab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non ascii character\n",
    "def non_ascii(s):\n",
    "  return \"\".join(i for i in s if ord(i)<128)\n",
    "\n",
    "def lower(text):\n",
    "  return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2b98cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove email address\n",
    "def email_address(text):\n",
    "  email = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "  return email.sub(r'',text)\n",
    "\n",
    "def punct(text):\n",
    "  token=RegexpTokenizer(r'\\w+')#regex\n",
    "  text = token.tokenize(text)\n",
    "  text= \" \".join(text)\n",
    "  return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e51ad188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "def removeStopWords(str):\n",
    "#select english stopwords\n",
    "  cachedStopWords = set(stopwords.words(\"english\"))\n",
    "#add custom words\n",
    "  cachedStopWords.update(('and','I','A','http','And','So','arnt','This','When','It','many','Many','so','cant','Yes','yes','No','no','These','these','mailto','regards','ayanna','like','email'))\n",
    "#remove stop words\n",
    "  new_str = ' '.join([word for word in str.split() if word not in cachedStopWords]) \n",
    "  return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "936aab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special characters removal\n",
    "def remove_(tweet):\n",
    "  tweet = re.sub('([_]+)', \"\", tweet)\n",
    "  return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "489dc77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply all the functions above\n",
    "#dfSentiment['hashtag'] = dfSentiment.tweet.apply(func = hashtags)\n",
    "dfSentiment['new_tweet'] = dfSentiment.tweet.apply(func = emoji)\n",
    "dfSentiment['new_tweet'] = dfSentiment.new_tweet.apply(func = remove_users)\n",
    "dfSentiment['new_tweet'] = dfSentiment.new_tweet.apply(func = clean_html)\n",
    "dfSentiment['new_tweet'] = dfSentiment.new_tweet.apply(func = remove_links)\n",
    "dfSentiment['new_tweet'] = dfSentiment.new_tweet.apply(func = non_ascii)\n",
    "dfSentiment['new_tweet'] = dfSentiment.new_tweet.apply(func = lower)\n",
    "dfSentiment['new_tweet'] = dfSentiment.new_tweet.apply(func = email_address)\n",
    "dfSentiment['new_tweet'] = dfSentiment.new_tweet.apply(func = removeStopWords)\n",
    "dfSentiment['new_tweet'] = dfSentiment.new_tweet.apply(func = clean_html)\n",
    "dfSentiment['new_tweet'] = dfSentiment.new_tweet.apply(func = punct)\n",
    "dfSentiment['new_tweet'] = dfSentiment.new_tweet.apply(func = remove_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd527ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>new_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1520266206548213760</td>\n",
       "      <td>When you‚Äôre stuck underneath a pup  \\n\\n#Albus...</td>\n",
       "      <td>youre stuck underneath pup albus albiedog pupp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1520342297728241664</td>\n",
       "      <td>Just posted a photo @ Organ Pipes National Par...</td>\n",
       "      <td>posted photo organ pipes national park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>493802764774825984</td>\n",
       "      <td>Finally home</td>\n",
       "      <td>finally home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>493802997793570817</td>\n",
       "      <td>When Harry met Anna üòâüòçüíï http://t.co/8cnpbUlnVz</td>\n",
       "      <td>harry met anna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>493803077489537024</td>\n",
       "      <td>Home Weather - Temp: 12.4 ¬∞C. Wind: 8.9 km/h N...</td>\n",
       "      <td>home weather temp 12 4 c wind 8 9 km h nne bar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>495508603722158080</td>\n",
       "      <td>@Flipltb and did u hold hands during dinner.</td>\n",
       "      <td>u hold hands dinner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>495508858987880448</td>\n",
       "      <td>Kicking people off tables coz we huuungry (@ C...</td>\n",
       "      <td>kicking people tables coz huuungry cornish arm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>495509181151989761</td>\n",
       "      <td>Lol that's why crusaders are the best counter ...</td>\n",
       "      <td>lol that s crusaders best counter attacking team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>495509245341614080</td>\n",
       "      <td>@takumiiiii0412 „Åì„Çå„ÅØÂèãÈÅî„ÅÆÂΩºÊ∞è„ÅÆÊÑöÁó¥„ÇíËÅû„ÅÑ„Å¶„Åü„ÅÆ(ÔΩ°ÔΩ•oÔΩ•ÔΩ°)üò¢ „Åã„ÄÅ„Åã„Åô...</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>495509322269351936</td>\n",
       "      <td>Home Weather - Temp: 6.3 ¬∞C. Wind: 2.0 km/h NE...</td>\n",
       "      <td>home weather temp 6 3 c wind 2 0 km h ne barom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                              tweet  \\\n",
       "0     1520266206548213760  When you‚Äôre stuck underneath a pup  \\n\\n#Albus...   \n",
       "1     1520342297728241664  Just posted a photo @ Organ Pipes National Par...   \n",
       "2      493802764774825984                                       Finally home   \n",
       "3      493802997793570817     When Harry met Anna üòâüòçüíï http://t.co/8cnpbUlnVz   \n",
       "4      493803077489537024  Home Weather - Temp: 12.4 ¬∞C. Wind: 8.9 km/h N...   \n",
       "...                   ...                                                ...   \n",
       "9995   495508603722158080       @Flipltb and did u hold hands during dinner.   \n",
       "9996   495508858987880448  Kicking people off tables coz we huuungry (@ C...   \n",
       "9997   495509181151989761  Lol that's why crusaders are the best counter ...   \n",
       "9998   495509245341614080  @takumiiiii0412 „Åì„Çå„ÅØÂèãÈÅî„ÅÆÂΩºÊ∞è„ÅÆÊÑöÁó¥„ÇíËÅû„ÅÑ„Å¶„Åü„ÅÆ(ÔΩ°ÔΩ•oÔΩ•ÔΩ°)üò¢ „Åã„ÄÅ„Åã„Åô...   \n",
       "9999   495509322269351936  Home Weather - Temp: 6.3 ¬∞C. Wind: 2.0 km/h NE...   \n",
       "\n",
       "                                              new_tweet  \n",
       "0     youre stuck underneath pup albus albiedog pupp...  \n",
       "1                posted photo organ pipes national park  \n",
       "2                                          finally home  \n",
       "3                                        harry met anna  \n",
       "4     home weather temp 12 4 c wind 8 9 km h nne bar...  \n",
       "...                                                 ...  \n",
       "9995                                u hold hands dinner  \n",
       "9996  kicking people tables coz huuungry cornish arm...  \n",
       "9997   lol that s crusaders best counter attacking team  \n",
       "9998                                                  o  \n",
       "9999  home weather temp 6 3 c wind 2 0 km h ne barom...  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12458149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99acfe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(review):\n",
    "    tokens = tokenizer.encode(review, return_tensors='pt')\n",
    "    result = model(tokens)\n",
    "    scores = result[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    #for i in range(scores.shape[0]):\n",
    "        #l = config.id2label[ranking[i]]\n",
    "        #s = scores[ranking[i]]\n",
    "        #print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "    \n",
    "    return (config.id2label[ranking[0]], scores[ranking[0]])\n",
    "\n",
    "dfSentiment['sentiment'] = dfSentiment['new_tweet'].apply(lambda x: sentiment_score(x[:512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d712d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>new_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1520266206548213760</td>\n",
       "      <td>When you‚Äôre stuck underneath a pup  \\n\\n#Albus...</td>\n",
       "      <td>youre stuck underneath pup albus albiedog pupp...</td>\n",
       "      <td>(Neutral, 0.82787895)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1520342297728241664</td>\n",
       "      <td>Just posted a photo @ Organ Pipes National Par...</td>\n",
       "      <td>posted photo organ pipes national park</td>\n",
       "      <td>(Neutral, 0.73221326)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>493802764774825984</td>\n",
       "      <td>Finally home</td>\n",
       "      <td>finally home</td>\n",
       "      <td>(Positive, 0.86881274)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>493802997793570817</td>\n",
       "      <td>When Harry met Anna üòâüòçüíï http://t.co/8cnpbUlnVz</td>\n",
       "      <td>harry met anna</td>\n",
       "      <td>(Neutral, 0.8515799)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>493803077489537024</td>\n",
       "      <td>Home Weather - Temp: 12.4 ¬∞C. Wind: 8.9 km/h N...</td>\n",
       "      <td>home weather temp 12 4 c wind 8 9 km h nne bar...</td>\n",
       "      <td>(Neutral, 0.85651684)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214394</th>\n",
       "      <td>551063864087814145</td>\n",
       "      <td>Mccrae St, Dandenong. #Other, going. Timeline:...</td>\n",
       "      <td>mccrae st dandenong other going timeline</td>\n",
       "      <td>(Neutral, 0.94569063)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214395</th>\n",
       "      <td>551066895634276354</td>\n",
       "      <td>‚Äú@samthaboss: @sireprince happy new year sire ...</td>\n",
       "      <td>happy new year sire mitchthanks bro</td>\n",
       "      <td>(Positive, 0.9689846)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214396</th>\n",
       "      <td>551067907669516289</td>\n",
       "      <td>Wind 12.2 km/h ENE. Barometer 1004.6 hPa, Risi...</td>\n",
       "      <td>wind 12 2 km h ene barometer 1004 6 hpa rising...</td>\n",
       "      <td>(Neutral, 0.84032524)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214397</th>\n",
       "      <td>551071551815049216</td>\n",
       "      <td>The mosquito bites are real tonight</td>\n",
       "      <td>mosquito bites real tonight</td>\n",
       "      <td>(Neutral, 0.5018282)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214398</th>\n",
       "      <td>551074763259392000</td>\n",
       "      <td>@AshyEllen how do you even have that many frie...</td>\n",
       "      <td>even friends 30 i m actually friends four</td>\n",
       "      <td>(Neutral, 0.74139804)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214399 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0       1520266206548213760   \n",
       "1       1520342297728241664   \n",
       "2        493802764774825984   \n",
       "3        493802997793570817   \n",
       "4        493803077489537024   \n",
       "...                     ...   \n",
       "214394   551063864087814145   \n",
       "214395   551066895634276354   \n",
       "214396   551067907669516289   \n",
       "214397   551071551815049216   \n",
       "214398   551074763259392000   \n",
       "\n",
       "                                                    tweet  \\\n",
       "0       When you‚Äôre stuck underneath a pup  \\n\\n#Albus...   \n",
       "1       Just posted a photo @ Organ Pipes National Par...   \n",
       "2                                            Finally home   \n",
       "3          When Harry met Anna üòâüòçüíï http://t.co/8cnpbUlnVz   \n",
       "4       Home Weather - Temp: 12.4 ¬∞C. Wind: 8.9 km/h N...   \n",
       "...                                                   ...   \n",
       "214394  Mccrae St, Dandenong. #Other, going. Timeline:...   \n",
       "214395  ‚Äú@samthaboss: @sireprince happy new year sire ...   \n",
       "214396  Wind 12.2 km/h ENE. Barometer 1004.6 hPa, Risi...   \n",
       "214397                The mosquito bites are real tonight   \n",
       "214398  @AshyEllen how do you even have that many frie...   \n",
       "\n",
       "                                                new_tweet  \\\n",
       "0       youre stuck underneath pup albus albiedog pupp...   \n",
       "1                  posted photo organ pipes national park   \n",
       "2                                            finally home   \n",
       "3                                          harry met anna   \n",
       "4       home weather temp 12 4 c wind 8 9 km h nne bar...   \n",
       "...                                                   ...   \n",
       "214394           mccrae st dandenong other going timeline   \n",
       "214395                happy new year sire mitchthanks bro   \n",
       "214396  wind 12 2 km h ene barometer 1004 6 hpa rising...   \n",
       "214397                        mosquito bites real tonight   \n",
       "214398          even friends 30 i m actually friends four   \n",
       "\n",
       "                     sentiment  \n",
       "0        (Neutral, 0.82787895)  \n",
       "1        (Neutral, 0.73221326)  \n",
       "2       (Positive, 0.86881274)  \n",
       "3         (Neutral, 0.8515799)  \n",
       "4        (Neutral, 0.85651684)  \n",
       "...                        ...  \n",
       "214394   (Neutral, 0.94569063)  \n",
       "214395   (Positive, 0.9689846)  \n",
       "214396   (Neutral, 0.84032524)  \n",
       "214397    (Neutral, 0.5018282)  \n",
       "214398   (Neutral, 0.74139804)  \n",
       "\n",
       "[214399 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2064987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSentiment.to_csv('tweets_classified.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d46cb69",
   "metadata": {},
   "source": [
    "### Topic Modelling"
   ]
  },
  {
   "cell_type": "raw",
   "id": "322b2a4d",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fc0682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f9d81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007c177ae5b64830b6bbf2f569745373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start with 10k tweets only\n",
    "embeddings = model.encode(dfSentiment[\"new_tweet\"], show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7ce8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "umap_embeddings = umap.UMAP(n_neighbors=15, \n",
    "                            n_components=5, \n",
    "                            metric='cosine').fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c2c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "cluster = hdbscan.HDBSCAN(min_cluster_size=15,\n",
    "                          metric='euclidean',                      \n",
    "                          cluster_selection_method='eom').fit(umap_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbeb289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data\n",
    "umap_data = umap.UMAP(n_neighbors=15, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)\n",
    "result = pd.DataFrame(umap_data, columns=['x', 'y'])\n",
    "result['labels'] = cluster.labels_\n",
    "\n",
    "# Visualize clusters\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "outliers = result.loc[result.labels == -1, :]\n",
    "clustered = result.loc[result.labels != -1, :]\n",
    "plt.scatter(outliers.x, outliers.y, color='#BDBDBD', s=0.05)\n",
    "plt.scatter(clustered.x, clustered.y, c=clustered.labels, s=0.05, cmap='hsv_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = list(dfSentiment[\"new_tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d955e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = pd.DataFrame(d, columns=[\"Doc\"])\n",
    "docs_df['Topic'] = cluster.labels_\n",
    "docs_df['Doc_ID'] = range(len(docs_df))\n",
    "docs_per_topic = docs_df.groupby(['Topic'], as_index = False).agg({'Doc': ' '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a3457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def c_tf_idf(documents, m, ngram_range=(1, 1)):\n",
    "    count = CountVectorizer(ngram_range=ngram_range, stop_words=\"english\").fit(documents)\n",
    "    t = count.transform(documents).toarray()\n",
    "    w = t.sum(axis=1)\n",
    "    tf = np.divide(t.T, w)\n",
    "    sum_t = t.sum(axis=0)\n",
    "    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n",
    "    tf_idf = np.multiply(tf, idf)\n",
    "\n",
    "    return tf_idf, count\n",
    "  \n",
    "tf_idf, count = c_tf_idf(docs_per_topic.Doc.values, m=len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0397dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20):\n",
    "    words = count.get_feature_names()\n",
    "    labels = list(docs_per_topic.Topic)\n",
    "    tf_idf_transposed = tf_idf.T\n",
    "    indices = tf_idf_transposed.argsort()[:, -n:]\n",
    "    top_n_words = {label: [(words[j], tf_idf_transposed[i][j]) for j in indices[i]][::-1] for i, label in enumerate(labels)}\n",
    "    return top_n_words\n",
    "\n",
    "def extract_topic_sizes(df):\n",
    "    topic_sizes = (df.groupby(['Topic'])\n",
    "                     .Doc\n",
    "                     .count()\n",
    "                     .reset_index()\n",
    "                     .rename({\"Topic\": \"Topic\", \"Doc\": \"Size\"}, axis='columns')\n",
    "                     .sort_values(\"Size\", ascending=False))\n",
    "    return topic_sizes\n",
    "\n",
    "top_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20)\n",
    "topic_sizes = extract_topic_sizes(docs_df); topic_sizes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771c2a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_n_words[1][:10]\n",
    "#top_n_words[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d082915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "for i in range(20):\n",
    "    # Calculate cosine similarity\n",
    "    similarities = cosine_similarity(tf_idf.T)\n",
    "    np.fill_diagonal(similarities, 0)\n",
    "\n",
    "    # Extract label to merge into and from where\n",
    "    topic_sizes = docs_df.groupby(['Topic']).count().sort_values(\"Doc\", ascending=False).reset_index()\n",
    "    topic_to_merge = topic_sizes.iloc[-1].Topic\n",
    "    topic_to_merge_into = np.argmax(similarities[topic_to_merge + 1]) - 1\n",
    "\n",
    "    # Adjust topics\n",
    "    docs_df.loc[docs_df.Topic == topic_to_merge, \"Topic\"] = topic_to_merge_into\n",
    "    old_topics = docs_df.sort_values(\"Topic\").Topic.unique()\n",
    "    map_topics = {old_topic: index - 1 for index, old_topic in enumerate(old_topics)}\n",
    "    docs_df.Topic = docs_df.Topic.map(map_topics)\n",
    "    docs_per_topic = docs_df.groupby(['Topic'], as_index = False).agg({'Doc': ' '.join})\n",
    "\n",
    "    # Calculate new topic words\n",
    "    m = len(data)\n",
    "    tf_idf, count = c_tf_idf(docs_per_topic.Doc.values, m)\n",
    "    top_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20)\n",
    "\n",
    "topic_sizes = extract_topic_sizes(docs_df); topic_sizes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be71111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_n_words[-1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d5e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd43887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec71ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516160bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
